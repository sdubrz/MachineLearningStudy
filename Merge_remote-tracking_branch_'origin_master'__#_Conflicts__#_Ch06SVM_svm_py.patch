Index: Tools/PreProcess.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- Tools/PreProcess.py	(date 1610712374176)
+++ Tools/PreProcess.py	(date 1610712374176)
@@ -0,0 +1,47 @@
+# 用于部分数据的预处理
+import numpy as np
+import os
+
+
+def standardize_array(array):
+    standardized_array = (array - np.mean(array, axis=0)) / np.std(array, axis=0)
+    return np.nan_to_num(standardized_array)
+
+
+def normalize(X, low=-1.0, up=1.0):
+    """
+    将数据的每一个维度都线性映射到 [low, up] 之间
+    :param X: 数据矩阵，每一行是一个样本
+    :param low: 下界
+    :param up: 上界
+    :return:
+    """
+    (n, dim) = X.shape
+    Y = np.zeros((n, dim))
+    for j in range(0, dim):
+        j_max = np.max(X[:, j])
+        j_min = np.min(X[:, j])
+
+        if j_max == j_min:
+            Y[:, j] = 0
+        else:
+            Y[:, j] = (X[:, j] - j_min)/(j_max-j_min)*(up-low) + low
+            # for i in range(0, n):
+            #     Y[i, j] = (Y[i, j] - j_min) / (j_max - j_min) * (up - low) + low
+
+    return Y
+
+
+def check_filepath(path):
+    """
+    通过向一个路径下存放一个很小的文件来检查该文件夹是否存在
+    避免出现存储结果时报错，以至于浪费时间的情况
+    :param path: 要检查的文件路径
+    :return:
+    """
+    if not os.path.exists(path):
+        os.makedirs(path)
+    data = np.array([[1, 2, 3],
+                     [4, 5, 6],
+                     [7, 8, 9]])
+    np.savetxt(path + "check_path.csv", data, fmt="%d", delimiter=",")
Index: Ch09Clustering/SpectralCluster.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- Ch09Clustering/SpectralCluster.py	(date 1610712374173)
+++ Ch09Clustering/SpectralCluster.py	(date 1610712374173)
@@ -0,0 +1,201 @@
+# 不进行正则化的谱聚类
+import numpy as np
+import matplotlib.pyplot as plt
+
+from Ch09Clustering import kmeans
+from sklearn import datasets
+from Tools import PreProcess
+from Ch10DimensionReduction import PCA
+from sklearn.cluster import spectral_clustering
+from sklearn.cluster import SpectralClustering
+
+
+"""
+    之前实验效果一直不好，经过检查，在计算 W 矩阵时，应该对其进行进一步的处理，使得 W 中每一行的和都为 1
+"""
+
+
+class SpectralCluster:
+    def __init__(self, X, k, delta=1.0, path=None):
+        """
+
+        :param X: 数据矩阵，每一行是一个样本
+        :param k: 要聚的类数
+        """
+        self.X = X
+        self.k = k
+        (n, dim) = X.shape
+        self.delta = delta
+        self.label = np.zeros((n, 1))
+        self.save_path = path
+
+    def gauss_similar(self, X, delta=1.0):
+        """
+        计算高斯的相似度
+        :param X: 数据矩阵，每一行是一个样本
+        :param delta: 高斯分布的方差
+        :return:
+        """
+        (n, dim) = X.shape
+        W = np.zeros((n, n))
+
+        for i in range(0, n):
+            for j in range(0, n):
+                d = np.linalg.norm(X[i, :] - X[j, :])
+                W[i, j] = np.exp(-d * d / (2 * delta * delta))
+            s = np.sum(W[i, :])
+            W[i, :] = W[i, :] / s
+            W[i, i] = 0
+        # np.savetxt('E:\\Project\\MachineLearning\\spectralClustering\\W.csv', W, fmt='%f', delimiter=',')
+        return W
+
+    def laplacian_matrix(self, X, delta=1.0):
+        """
+        计算拉普拉斯矩阵
+        :param X: 数据矩阵，每一行是一个样本
+        :param delta: 高斯分布的方差
+        :return:
+        """
+        (n, dim) = X.shape
+        W = self.gauss_similar(X, delta=delta)
+        D = np.zeros((n, n))
+        for i in range(0, n):
+            D[i, i] = np.sum(W[i, :])
+
+        L = D - W
+        # np.savetxt('E:\\Project\\MachineLearning\\spectralClustering\\L.csv', L, fmt='%f', delimiter=',')
+        return L
+
+    def clustering(self, X, k, delta=1.0):
+        """
+        聚类
+        :param X: 数据矩阵，每一行是一个样本
+        :param k: 簇的数目
+        :param delta: 计算高斯相似度时用的方差，从t-SNE的经验来看，所有的数据都共用一个方差其实是很不合适的
+        :return:
+        """
+        (n, dim) = X.shape
+        L = self.laplacian_matrix(X, delta=delta)
+        eg_values, eg_vectors = np.linalg.eig(L)
+        idx = eg_values.argsort()
+        eg_vectors = eg_vectors[:, idx]
+
+        print(eg_values)
+
+        U = eg_vectors[:, 0:k]
+        # U = eg_vectors[:, n-k:n]  # 一个实验
+        # np.savetxt('E:\\Project\\MachineLearning\\spectralClustering\\U.csv', U, fmt='%f', delimiter=',')
+        # np.savetxt('E:\\Project\\MachineLearning\\spectralClustering\\eigenvectors.csv', eg_vectors, fmt='%f', delimiter=',')
+        k_means = kmeans.K_means(U, k)
+        label = k_means.fit_transform()
+
+        return label
+
+    def fit_transform(self):
+        self.label = self.clustering(self.X, self.k, self.delta)
+        return self.label
+
+
+def test():
+    """用实际数据进行测试"""
+    # wine = datasets.load_iris()
+    # X = wine.data
+    # label_true = wine.target
+
+    main_path = 'E:\\Project\\result2019\\TPCA1008\\'
+    data_name = 'Wine'
+    read_path = main_path + "datasets\\" + data_name + "\\"
+    data_reader = np.loadtxt(read_path+'data.csv', dtype=np.str, delimiter=',')
+    label_reader = np.loadtxt(read_path+'label.csv', dtype=np.str, delimiter=',')
+    X = data_reader[:, :].astype(np.float)
+    label_true = label_reader.astype(np.int)
+
+    X = PreProcess.normalize(X)
+    (n, dim) = X.shape
+    k = 3
+    delta = 1.0  # 这个方差的取值也很重要
+
+    spectral_cluster = SpectralCluster(X, k, delta=delta)
+    label = spectral_cluster.fit_transform()
+    pca = PCA.PCA(X, 2)
+    Y = pca.fit_transform()
+
+    colors = ['c', 'm', 'y', 'b', 'r', 'g']
+    shapes = ['s', 'o', '^', 'p', '+', '*']
+    for i in range(0, n):
+        plt.scatter(Y[i, 0], Y[i, 1], c=colors[int(label[i])], marker=shapes[int(label_true[i])])
+
+    plt.show()
+
+
+def sklearn_test():
+    """
+    用sklearn中的谱聚类方法实验
+    :return:
+    """
+    # wine = datasets.load_iris()
+    # X = wine.data
+    # label_true = wine.target
+
+    main_path = 'E:\\Project\\result2019\\TPCA1008\\'
+    data_name = 'digits5_8'
+    read_path = main_path + "datasets\\" + data_name + "\\"
+    data_reader = np.loadtxt(read_path + 'data.csv', dtype=np.str, delimiter=',')
+    label_reader = np.loadtxt(read_path + 'label.csv', dtype=np.str, delimiter=',')
+    X = data_reader[:, :].astype(np.float)
+    label_true = label_reader.astype(np.int)
+
+    X = PreProcess.normalize(X)
+    (n, dim) = X.shape
+    k = 5
+    delta = 1.0
+
+    affinity = SpectralCluster.gauss_similar(None, X=X, delta=delta)
+    label = spectral_clustering(affinity, n_clusters=k)
+
+    pca = PCA.PCA(X, 2)
+    Y = pca.fit_transform()
+
+    colors = ['c', 'm', 'y', 'b', 'r', 'g']
+    shapes = ['s', 'o', '^', 'p', '+', '*']
+    for i in range(0, n):
+        plt.scatter(Y[i, 0], Y[i, 1], c=colors[int(label[i])], marker=shapes[int(label_true[i])])
+
+    plt.show()
+
+
+def sklearn_test2():
+    read_path = 'F:\\result2019-2\\result0812\\datasets\\Wine\\'
+    data_reader = np.loadtxt(read_path + 'data.csv', dtype=np.str, delimiter=',')
+    label_reader = np.loadtxt(read_path + 'label.csv', dtype=np.str, delimiter=',')
+    X = data_reader[:, :].astype(np.float)
+    label_true = label_reader.astype(np.int)
+
+    X = PreProcess.normalize(X)
+    (n, dim) = X.shape
+    k = 3
+    delta = 1.0
+
+    sc = SpectralClustering(n_clusters=k)
+    sc.fit(X)
+    label = sc.labels_
+
+    pca = PCA.PCA(X, 2)
+    Y = pca.fit_transform()
+
+    colors = ['c', 'm', 'y', 'b', 'r', 'g']
+    shapes = ['s', 'o', '^', 'p', '+', '*']
+    for i in range(0, n):
+        plt.scatter(Y[i, 0], Y[i, 1], c=colors[int(label[i])], marker=shapes[int(label_true[i])])
+
+    plt.show()
+
+
+if __name__ == '__main__':
+    test()
+    # sklearn_test2()
+
+
+
+
+
Index: Ch09Clustering/SpectralCluster2.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- Ch09Clustering/SpectralCluster2.py	(date 1610712374174)
+++ Ch09Clustering/SpectralCluster2.py	(date 1610712374174)
@@ -0,0 +1,127 @@
+# K近邻的谱聚类实现
+import numpy as np
+from sklearn.neighbors import NearestNeighbors
+from Ch09Clustering.kmeans import K_means
+from Ch10DimensionReduction import PCA
+from Tools import PreProcess
+import matplotlib.pyplot as plt
+from sklearn.manifold import TSNE
+
+
+"""
+    计算拉普拉斯矩阵的时候，如果采用的是标准的 L = D - W
+    则应该将 L 特征值分解所得到的最小的 k 个特征值所对应的特征向量作为 k-means 算法的输入；
+    而如果采用的是 L = D + W
+    则应该将最大的 k 个特征值所对应的特征向量作为 k-means 算法的输入。
+    在计算 W 时应该进行处理，使得 W 中每一行的和都为 1
+"""
+
+
+def similar(data, i, j):
+    """计算相似度"""
+    norm = np.linalg.norm(data[i, :] - data[j, :])
+    delta = 1.0  # 感觉所有的点都用相同的方差值会有问题的
+    return np.exp(-norm*norm/(2*delta*delta))
+
+
+def laplace_matrix(data, n_nbrs, save_path=None):
+    """
+    计算拉普拉斯矩阵
+    :param data: 数据矩阵，每一行是一个样本
+    :param n_nbrs: K近邻的K
+    :param save_path: 保存中间结果的文件目录，用于程序调试
+    :return:
+    """
+    (n, dim) = data.shape
+    W = np.zeros((n, n))
+
+    neighbors = NearestNeighbors(n_neighbors=n_nbrs, algorithm='ball_tree').fit(data)
+    distance, nbs_index = neighbors.kneighbors(data)
+
+    for i in range(0, n):
+        for j in range(i+1, n):
+            if j in nbs_index[i, :]:
+                W[i, j] = similar(data, i, j)
+                W[j, i] = W[i, j]
+        W[i, i] = 0
+
+    if not(save_path is None):
+        np.savetxt(save_path+"similar_matrix.csv", W, fmt='%f', delimiter=',')
+
+    for i in range(0, n):
+        s = np.sum(W[i, :])
+        if s == 0:
+            continue
+        W[i, :] = -1 * W[i, :] / s
+        W[i, i] = 1
+
+    return W
+
+
+def spectral_cluster(data, n_cluster=3, n_nbrs=15, save_path=None):
+    """
+    K近邻图的谱聚类方法，未进行正则化
+    :param data: 数据矩阵，每一行是一个样本
+    :param n_cluster: 聚类的簇数
+    :param n_nbrs: 近邻数
+    :param save_path: 保存中间结果的文件路径，用于程序调试
+    :return:
+    """
+    (n, dim) = data.shape
+    L = laplace_matrix(data, n_nbrs, save_path=save_path)
+    np.savetxt(save_path+"laplace matrix.csv", L, fmt='%f', delimiter=',')
+
+    eigen_values, eigen_vectors = np.linalg.eig(L)
+    idx = eigen_values.argsort()
+    eigen_vectors = eigen_vectors[:, idx]
+
+    np.savetxt(save_path+"eigenvectors.csv", eigen_vectors, fmt='%f', delimiter=',')
+    np.savetxt(save_path+"eigenvalues.csv", eigen_values[idx], fmt='%f', delimiter=',')
+
+    # eigen_data = eigen_vectors[:, n-n_cluster:n]
+    eigen_data = eigen_vectors[:, 0:n_cluster]
+    np.savetxt(save_path+"eigendata.csv", eigen_data, fmt='%f', delimiter=',')
+    kmeans = K_means(eigen_data, n_cluster)
+    label = kmeans.fit_transform()
+
+    return label
+
+
+def run_test():
+    main_path = 'E:\\Project\\result2019\\TPCA1008\\'
+    data_name = 'digits5_8'
+    read_path = main_path + "datasets\\" + data_name + "\\"
+    data_reader = np.loadtxt(read_path + 'data.csv', dtype=np.str, delimiter=',')
+    label_reader = np.loadtxt(read_path + 'label.csv', dtype=np.str, delimiter=',')
+    X = data_reader[:, :].astype(np.float)
+    label_true = label_reader.astype(np.int)
+
+    X = PreProcess.normalize(X)
+    (n, dim) = X.shape
+    n_clusters = 5
+    n_nbrs = 15
+
+    save_path = main_path + "spectralCluster\\" + data_name + "\\"
+    PreProcess.check_filepath(save_path)
+
+    label = spectral_cluster(X, n_clusters, n_nbrs, save_path=save_path)
+
+    tsne = TSNE(n_components=2, perplexity=30.0)
+    Y = tsne.fit_transform(X)
+
+    colors = ['c', 'm', 'y', 'b', 'r', 'g']
+    shapes = ['s', 'o', '^', 'p', '+', '*']
+    for i in range(0, n):
+        plt.scatter(Y[i, 0], Y[i, 1], c=colors[int(label[i])], marker=shapes[int(label_true[i])])
+
+    plt.show()
+
+
+def test():
+    m = 10
+    a = [0 for x in range(m)]
+    print(a)
+
+
+if __name__ == '__main__':
+    run_test()
Index: Ch10DimensionReduction/PCA.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- Ch10DimensionReduction/PCA.py	(date 1610712374175)
+++ Ch10DimensionReduction/PCA.py	(date 1610712374175)
@@ -0,0 +1,49 @@
+# PCA降维方法
+import numpy as np
+import matplotlib.pyplot as plt
+
+from sklearn import datasets
+from Tools import PreProcess
+
+
+class PCA:
+    def __init__(self, X, n_dims):
+        """
+
+        :param X: 要进行降维的数据矩阵，每一行是一个样本
+        :param n_dims: 降维之后的维度数
+        """
+        self.X = X
+        self.n_dims = n_dims
+        self.Y = None  # 降维结果
+
+    def fit_transform(self):
+        (n, dim) = self.X.shape
+        X2 = self.X - np.mean(self.X, axis=0)
+        C = np.dot(X2.T, X2)
+
+        eg_values, eg_vectors = np.linalg.eig(C)
+        idx = (eg_values*-1).argsort()
+
+        eg_vectors = eg_vectors[:, idx]
+        P = eg_vectors[:, 0:self.n_dims]
+
+        self.Y = np.matmul(X2, P)
+        return self.Y
+
+
+def test():
+    data = datasets.load_wine()
+    X = data.data
+    X = PreProcess.normalize(X)
+    label = data.target
+
+    pca = PCA(X, 2)
+    Y = pca.fit_transform()
+    plt.scatter(Y[:, 0], Y[:, 1], c=label)
+
+    plt.show()
+
+
+if __name__ == '__main__':
+    test()
Index: .idea/misc.xml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- .idea/misc.xml	(date 1610712361000)
+++ .idea/misc.xml	(date 1610712374184)
@@ -1,4 +1,8 @@
 <?xml version="1.0" encoding="UTF-8"?>
 <project version="4">
+<<<<<<< HEAD
   <component name="ProjectRootManager" version="2" project-jdk-name="Python 3.7 (Python) (3)" project-jdk-type="Python SDK" />
+=======
+  <component name="ProjectRootManager" version="2" project-jdk-name="Python 3.7" project-jdk-type="Python SDK" />
+>>>>>>> origin/master
 </project>
\ No newline at end of file
Index: .idea/MachineLearningStudy.iml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- .idea/MachineLearningStudy.iml	(date 1610712361000)
+++ .idea/MachineLearningStudy.iml	(date 1610712379744)
@@ -4,7 +4,7 @@
     <content url="file://$MODULE_DIR$">
       <excludeFolder url="file://$MODULE_DIR$/venv" />
     </content>
-    <orderEntry type="jdk" jdkName="Python 3.7 (Python) (3)" jdkType="Python SDK" />
+    <orderEntry type="jdk" jdkName="Python 3.7" jdkType="Python SDK" />
     <orderEntry type="sourceFolder" forTests="false" />
     <orderEntry type="library" name="R User Library" level="project" />
     <orderEntry type="library" name="R Skeletons" level="application" />
Index: Ch09Clustering/kmeans.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- Ch09Clustering/kmeans.py	(date 1610712361000)
+++ Ch09Clustering/kmeans.py	(date 1610712374175)
@@ -9,6 +9,8 @@
 
 class K_means:
 
+    MAX_LOOP = 3000  # 最大的循环次数
+
     def __init__(self, X, k):
         """
         初始化方法
@@ -54,9 +56,13 @@
                 center[i, :] = center_sum[i, :] / center_count[i]
 
             self.loop_time += 1
+            if self.loop_time > self.MAX_LOOP:
+                print('k-means:\t已达到最大的迭代次数')
+                break
 
         self.center_points = center
         self.label = label
+        print('k-means:\t迭代的总次数是 ', self.loop_time)
 
     def fit_transform(self):
         self.run(self.X, self.k)
